---
title: "Clustering y arbol de decisiones"
author: "Adrian Israel Castillo Lara"
date: ""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(factoextra)
library(cowplot)
library(ggpubr)
library(cluster)
library(purrr)
library(dplyr)
```

```{r}
data3<-read.csv('C:/Users/rusoc/OneDrive/Escritorio/TEC/Mineria de datos/Wine.csv')
```
Clustering

```{r}
#Quitamos columnas que no nos sirven para el analisis
data3<- data3[,-12]
```

```{r}
#Estandarizamos los datos
dataestand = scale(data3, center = TRUE, scale = TRUE)
dataestand = as.data.frame(dataestand)
```

```{r}
#Buscamos el numero optimo de clusters
optimo <- fviz_nbclust(dataestand, kmeans, method = "wss")
optimo

```

```{r}
# Encontramos que el numero optimo es 3, hacemos el kmeans clustering
kmdata<-kmeans(dataestand, centers = 3)
kmdata
```

```{r}
#Visualizamos el Kmeas clustering
clusterdata <- kmdata$cluster

(dataplot=ggplot(dataestand, aes(x = Color.intensity, y = Alcohol)) +
    geom_point(aes(color=as.factor(clusterdata)), size=5)+
    geom_text(aes(label = clusterdata), size = 3) +
    theme_bw() +
    theme(legend.position = "none")+
    labs(title = "Kmenas con k=3")) 
```

Arbol de decisiones

```{r}
# Selección muestra entrenamiento de un 70%
library(tree)
library(dplyr)
train <- sample(seq(length(data3$Alcohol)), length(data3$Alcohol) * 0.7, replace = FALSE)

```

```{r}
# Creación del árbol de clasificación
data3.tree <- tree(data3$Alcohol ~ Color.intensity, data3, subset = train)

```

```{r}
# Visualización del árbol
plot(data3.tree)
text(data3.tree, pretty = 0)
```

```{r}
# Ver los valores del árbol
data3.tree
```

```{r}
#PREDICCIONES
test <- setdiff(seq(length(data3$Alcohol)), train)
tree.pred <- predict(data3.tree, data3[test, ])
summary(tree.pred)
```

```{r}
result_table <- with(data3[test, ], table(tree.pred, Alcohol))
print(result_table)
```

